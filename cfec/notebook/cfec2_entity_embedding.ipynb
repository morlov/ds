{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import metrics, preprocessing\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "from keras import optimizers\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import utils\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import category_encoders as ce\n",
    "import numpy as np\n",
    "import datetime\n",
    "import itertools\n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:39,  7.89s/it]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../data/train.csv')\n",
    "df_test = pd.read_csv('../data/test.csv')\n",
    "\n",
    "mapping_ord1 = {'Unknown': 0, 'Novice': 1, 'Expert': 2, 'Contributor': 3, 'Master': 4, 'Grandmaster': 5}\n",
    "mapping_ord2 = {'Unknown': 0, 'Freezing': 1, 'Cold': 2, 'Warm': 3, 'Hot': 4, 'Boiling Hot': 5, 'Lava Hot': 6}\n",
    "mapping_ord3 = dict([(v, i) for i, v in enumerate(sorted(set(df['ord_3'].fillna(\"0\"))))])\n",
    "mapping_ord4 = dict([(v, i) for i, v in enumerate(sorted(set(df['ord_4'].fillna(\"0\"))))])\n",
    "mapping_ord5 = dict([(v, i) for i, v in enumerate(sorted(set(df['ord_5'].fillna(\"0\"))))])\n",
    "\n",
    "def preprocess_data(df):\n",
    "    df['ord_0'] = df['ord_0'].fillna(0)\n",
    "    df['ord_1'] =  df['ord_1'].fillna('Unknown').map(mapping_ord1)\n",
    "    df['ord_2'] =  df['ord_2'].fillna('Unknown').map(mapping_ord2)\n",
    "    df['ord_3'] =  df['ord_3'].fillna('0').map(mapping_ord3)\n",
    "    df['ord_4'] =  df['ord_4'].fillna('0').map(mapping_ord4)\n",
    "    df['ord_5'] =  df['ord_5'].fillna('0').map(mapping_ord5)\n",
    "    df['bin_3'] = df['bin_3'].fillna('U').map({\"T\": 1, \"F\": 0, \"U\": np.nan})\n",
    "    df['bin_4'] = df['bin_4'].fillna('U').map({\"Y\": 1, \"N\": 0, \"U\": np.nan})\n",
    "    return df\n",
    "\n",
    "def encode(df, df_test, cols):\n",
    "    cols_enc = list(map(lambda x: x + \"_enc\", cols))\n",
    "    for c in cols_enc:\n",
    "        df[c] = np.nan\n",
    "        df_test[c] = np.nan\n",
    "        \n",
    "    skf = StratifiedKFold(n_splits=5, random_state=42, shuffle=True)\n",
    "    \n",
    "    for train_idx, oof_idx in tqdm(skf.split(df, df[\"target\"])):\n",
    "        enc = ce.TargetEncoder(cols = cols, smoothing=0.3)\n",
    "        enc.fit(df.loc[train_idx, cols], df.loc[train_idx, \"target\"])\n",
    "        df.loc[oof_idx, cols_enc] = enc.transform(df.loc[oof_idx, cols]).values\n",
    "    \n",
    "    enc = ce.TargetEncoder(cols = cols, smoothing=0.3)\n",
    "    enc.fit(df[cols], df[\"target\"])\n",
    "    df_test[cols_enc] = enc.transform(df_test[cols])\n",
    "    return df, df_test, cols_enc\n",
    "    \n",
    "df = preprocess_data(df)\n",
    "df_test = preprocess_data(df_test)\n",
    "\n",
    "binary = ['bin_0', 'bin_1', 'bin_2', 'bin_3', 'bin_4']\n",
    "ordinal  = ['ord_0', 'ord_1', 'ord_2', 'ord_3', 'ord_4', 'ord_5']\n",
    "low_card = ['nom_0', 'nom_1', 'nom_2', 'nom_3', 'nom_4']\n",
    "high_card = ['nom_5', 'nom_6', 'nom_7', 'nom_8', 'nom_9']\n",
    "date = ['day', 'month']\n",
    "\n",
    "features = high_card + low_card + date # + ordinal + binary\n",
    "\n",
    "df, df_test, features_enc =  encode(df, df_test, features)\n",
    "\n",
    "for c in features:\n",
    "    enc = preprocessing.LabelEncoder()\n",
    "    enc.fit(pd.concat([df, df_test], sort=False)[c].fillna(-1).astype(str))\n",
    "    df[c] = enc.transform(df[c].fillna(-1).astype(str))\n",
    "    df_test[c] = enc.transform(df_test[c].fillna(-1).astype(str))\n",
    "    \n",
    "features_all = features  + features_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(df, cols_te, cols_emb):    \n",
    "    \n",
    "    inputs = []\n",
    "    outputs = []\n",
    "    \n",
    "    reg = regularizers.l1_l2(l1=1e-5, l2=1e-5)\n",
    "    \n",
    "    inp_dense = layers.Input(shape=(len(cols_te),))\n",
    "    x_dense = layers.Dense(32, activation=\"relu\")(inp_dense)\n",
    "    x_dense = layers.Dropout(0.3)(x_dense)\n",
    "    out_dense = layers.BatchNormalization()(x_dense)\n",
    "    \n",
    "    inputs.append(inp_dense)\n",
    "    outputs.append(out_dense)\n",
    "    \n",
    "    for c in cols_emb:\n",
    "        nunique = int(df[c].nunique())\n",
    "        emb_dim = int(min(np.ceil((nunique)/2), 64))\n",
    "        inp = layers.Input(shape=(1,))\n",
    "        out = layers.Embedding(nunique + 1, emb_dim, name=c, embeddings_regularizer=reg)(inp)\n",
    "        out = layers.SpatialDropout1D(0.3)(out)\n",
    "            \n",
    "        out = layers.Reshape(target_shape=(emb_dim, ))(out)\n",
    "        inputs.append(inp)\n",
    "        outputs.append(out)\n",
    "    \n",
    "    x = layers.Concatenate(name=\"embeddings\")(outputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    \n",
    "    x = layers.Dense(128, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    \n",
    "    x = layers.Dense(128, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    \n",
    "    y = layers.Dense(2, activation=\"softmax\")(x)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=y)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auc(y_true, y_pred):\n",
    "    def fallback_auc(y_true, y_pred):\n",
    "        try:\n",
    "            return metrics.roc_auc_score(y_true, y_pred)\n",
    "        except:\n",
    "            return 0.5\n",
    "    return tf.py_function(fallback_auc, (y_true, y_pred), tf.double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_layer_output(X, model):\n",
    "    layer = Model(inputs=model.input, outputs=model.get_layer(\"embeddings\").output)\n",
    "    out = emd_layer.predict(X)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 540000 samples, validate on 60000 samples\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "540000/540000 [==============================] - 16s 30us/sample - loss: 0.5568 - auc: 0.7029 - val_loss: 0.4665 - val_auc: 0.7831\n",
      "Epoch 2/100\n",
      "540000/540000 [==============================] - 9s 17us/sample - loss: 0.4550 - auc: 0.7759 - val_loss: 0.4367 - val_auc: 0.7838\n",
      "Epoch 3/100\n",
      "540000/540000 [==============================] - 9s 16us/sample - loss: 0.4315 - auc: 0.7815 - val_loss: 0.4237 - val_auc: 0.7833\n",
      "Epoch 4/100\n",
      "540000/540000 [==============================] - 9s 16us/sample - loss: 0.4227 - auc: 0.7839 - val_loss: 0.4195 - val_auc: 0.7834\n",
      "Epoch 5/100\n",
      "539648/540000 [============================>.] - ETA: 0s - loss: 0.4204 - auc: 0.7845\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "540000/540000 [==============================] - 9s 16us/sample - loss: 0.4204 - auc: 0.7845 - val_loss: 0.4184 - val_auc: 0.7835\n",
      "Epoch 6/100\n",
      "540000/540000 [==============================] - 9s 16us/sample - loss: 0.4140 - auc: 0.7881 - val_loss: 0.4151 - val_auc: 0.7830\n",
      "Epoch 7/100\n",
      "536576/540000 [============================>.] - ETA: 0s - loss: 0.4134 - auc: 0.7887Restoring model weights from the end of the best epoch.\n",
      "540000/540000 [==============================] - 9s 16us/sample - loss: 0.4135 - auc: 0.7886 - val_loss: 0.4165 - val_auc: 0.7825\n",
      "Epoch 00007: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1it [02:03, 123.49s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 540000 samples, validate on 60000 samples\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "540000/540000 [==============================] - 12s 23us/sample - loss: 0.5519 - auc: 0.7024 - val_loss: 0.4624 - val_auc: 0.7837\n",
      "Epoch 2/100\n",
      "540000/540000 [==============================] - 9s 17us/sample - loss: 0.4527 - auc: 0.7757 - val_loss: 0.4336 - val_auc: 0.7850\n",
      "Epoch 3/100\n",
      "540000/540000 [==============================] - 9s 17us/sample - loss: 0.4299 - auc: 0.7813 - val_loss: 0.4213 - val_auc: 0.7848\n",
      "Epoch 4/100\n",
      "540000/540000 [==============================] - 9s 17us/sample - loss: 0.4223 - auc: 0.7831 - val_loss: 0.4178 - val_auc: 0.7852\n",
      "Epoch 5/100\n",
      "540000/540000 [==============================] - 9s 17us/sample - loss: 0.4204 - auc: 0.7838 - val_loss: 0.4170 - val_auc: 0.7850\n",
      "Epoch 6/100\n",
      "540000/540000 [==============================] - 10s 18us/sample - loss: 0.4195 - auc: 0.7852 - val_loss: 0.4170 - val_auc: 0.7848\n",
      "Epoch 7/100\n",
      "537600/540000 [============================>.] - ETA: 0s - loss: 0.4195 - auc: 0.7858\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "540000/540000 [==============================] - 10s 18us/sample - loss: 0.4194 - auc: 0.7858 - val_loss: 0.4178 - val_auc: 0.7847\n",
      "Epoch 8/100\n",
      "540000/540000 [==============================] - 9s 17us/sample - loss: 0.4130 - auc: 0.7895 - val_loss: 0.4152 - val_auc: 0.7841\n",
      "Epoch 9/100\n",
      "537600/540000 [============================>.] - ETA: 0s - loss: 0.4129 - auc: 0.7903Restoring model weights from the end of the best epoch.\n",
      "540000/540000 [==============================] - 9s 17us/sample - loss: 0.4128 - auc: 0.7903 - val_loss: 0.4178 - val_auc: 0.7838\n",
      "Epoch 00009: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2it [04:15, 126.14s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 540000 samples, validate on 60000 samples\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "540000/540000 [==============================] - 13s 25us/sample - loss: 0.5453 - auc: 0.7082 - val_loss: 0.4588 - val_auc: 0.7868\n",
      "Epoch 2/100\n",
      "540000/540000 [==============================] - 9s 18us/sample - loss: 0.4508 - auc: 0.7761 - val_loss: 0.4294 - val_auc: 0.7872\n",
      "Epoch 3/100\n",
      "540000/540000 [==============================] - 10s 18us/sample - loss: 0.4290 - auc: 0.7813 - val_loss: 0.4188 - val_auc: 0.7871\n",
      "Epoch 4/100\n",
      "540000/540000 [==============================] - 9s 17us/sample - loss: 0.4221 - auc: 0.7828 - val_loss: 0.4159 - val_auc: 0.7872\n",
      "Epoch 5/100\n",
      "538624/540000 [============================>.] - ETA: 0s - loss: 0.4201 - auc: 0.7843\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "540000/540000 [==============================] - 9s 17us/sample - loss: 0.4201 - auc: 0.7842 - val_loss: 0.4149 - val_auc: 0.7872\n",
      "Epoch 6/100\n",
      "540000/540000 [==============================] - 10s 18us/sample - loss: 0.4139 - auc: 0.7873 - val_loss: 0.4124 - val_auc: 0.7861\n",
      "Epoch 7/100\n",
      "537600/540000 [============================>.] - ETA: 0s - loss: 0.4137 - auc: 0.7879Restoring model weights from the end of the best epoch.\n",
      "540000/540000 [==============================] - 9s 17us/sample - loss: 0.4136 - auc: 0.7880 - val_loss: 0.4135 - val_auc: 0.7859\n",
      "Epoch 00007: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "3it [06:12, 123.28s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 540000 samples, validate on 60000 samples\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "540000/540000 [==============================] - 13s 25us/sample - loss: 0.5591 - auc: 0.7013 - val_loss: 0.4651 - val_auc: 0.7866\n",
      "Epoch 2/100\n",
      "540000/540000 [==============================] - 10s 18us/sample - loss: 0.4554 - auc: 0.7761 - val_loss: 0.4348 - val_auc: 0.7870\n",
      "Epoch 3/100\n",
      "540000/540000 [==============================] - 9s 17us/sample - loss: 0.4323 - auc: 0.7815 - val_loss: 0.4213 - val_auc: 0.7872\n",
      "Epoch 4/100\n",
      "540000/540000 [==============================] - 10s 18us/sample - loss: 0.4235 - auc: 0.7832 - val_loss: 0.4183 - val_auc: 0.7866\n",
      "Epoch 5/100\n",
      "540000/540000 [==============================] - 10s 18us/sample - loss: 0.4213 - auc: 0.7843 - val_loss: 0.4179 - val_auc: 0.7871\n",
      "Epoch 6/100\n",
      "539648/540000 [============================>.] - ETA: 0s - loss: 0.4203 - auc: 0.7856\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "540000/540000 [==============================] - 10s 19us/sample - loss: 0.4203 - auc: 0.7854 - val_loss: 0.4175 - val_auc: 0.7868\n",
      "Epoch 7/100\n",
      "540000/540000 [==============================] - 10s 19us/sample - loss: 0.4143 - auc: 0.7887 - val_loss: 0.4143 - val_auc: 0.7857\n",
      "Epoch 8/100\n",
      "539648/540000 [============================>.] - ETA: 0s - loss: 0.4139 - auc: 0.7896Restoring model weights from the end of the best epoch.\n",
      "540000/540000 [==============================] - 11s 20us/sample - loss: 0.4139 - auc: 0.7895 - val_loss: 0.4157 - val_auc: 0.7856\n",
      "Epoch 00008: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "4it [08:22, 125.32s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 540000 samples, validate on 60000 samples\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "540000/540000 [==============================] - 13s 24us/sample - loss: 0.5536 - auc: 0.7005 - val_loss: 0.4637 - val_auc: 0.7827\n",
      "Epoch 2/100\n",
      "540000/540000 [==============================] - 9s 17us/sample - loss: 0.4537 - auc: 0.7753 - val_loss: 0.4343 - val_auc: 0.7846\n",
      "Epoch 3/100\n",
      "540000/540000 [==============================] - 9s 17us/sample - loss: 0.4303 - auc: 0.7817 - val_loss: 0.4217 - val_auc: 0.7842\n",
      "Epoch 4/100\n",
      "540000/540000 [==============================] - 9s 17us/sample - loss: 0.4222 - auc: 0.7833 - val_loss: 0.4180 - val_auc: 0.7846\n",
      "Epoch 5/100\n",
      "537600/540000 [============================>.] - ETA: 0s - loss: 0.4194 - auc: 0.7846\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "540000/540000 [==============================] - 10s 18us/sample - loss: 0.4194 - auc: 0.7845 - val_loss: 0.4166 - val_auc: 0.7845\n",
      "Epoch 6/100\n",
      "540000/540000 [==============================] - 10s 19us/sample - loss: 0.4133 - auc: 0.7877 - val_loss: 0.4144 - val_auc: 0.7840\n",
      "Epoch 7/100\n",
      "537600/540000 [============================>.] - ETA: 0s - loss: 0.4127 - auc: 0.7883Restoring model weights from the end of the best epoch.\n",
      "540000/540000 [==============================] - 10s 19us/sample - loss: 0.4128 - auc: 0.7882 - val_loss: 0.4145 - val_auc: 0.7840\n",
      "Epoch 00007: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "5it [10:19, 122.81s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 540000 samples, validate on 60000 samples\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "540000/540000 [==============================] - 14s 26us/sample - loss: 0.5530 - auc: 0.7010 - val_loss: 0.4614 - val_auc: 0.7876\n",
      "Epoch 2/100\n",
      "540000/540000 [==============================] - 10s 19us/sample - loss: 0.4539 - auc: 0.7753 - val_loss: 0.4333 - val_auc: 0.7881\n",
      "Epoch 3/100\n",
      "540000/540000 [==============================] - 10s 19us/sample - loss: 0.4314 - auc: 0.7812 - val_loss: 0.4211 - val_auc: 0.7881\n",
      "Epoch 4/100\n",
      "540000/540000 [==============================] - 10s 19us/sample - loss: 0.4238 - auc: 0.7830 - val_loss: 0.4169 - val_auc: 0.7886\n",
      "Epoch 5/100\n",
      "540000/540000 [==============================] - 10s 19us/sample - loss: 0.4215 - auc: 0.7839 - val_loss: 0.4169 - val_auc: 0.7884\n",
      "Epoch 6/100\n",
      "540000/540000 [==============================] - 10s 19us/sample - loss: 0.4203 - auc: 0.7849 - val_loss: 0.4153 - val_auc: 0.7887\n",
      "Epoch 7/100\n",
      "540000/540000 [==============================] - 10s 18us/sample - loss: 0.4201 - auc: 0.7856 - val_loss: 0.4165 - val_auc: 0.7883\n",
      "Epoch 8/100\n",
      "540000/540000 [==============================] - 10s 19us/sample - loss: 0.4198 - auc: 0.7867 - val_loss: 0.4162 - val_auc: 0.7885\n",
      "Epoch 9/100\n",
      "537600/540000 [============================>.] - ETA: 0s - loss: 0.4201 - auc: 0.7875\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "540000/540000 [==============================] - 10s 19us/sample - loss: 0.4200 - auc: 0.7875 - val_loss: 0.4177 - val_auc: 0.7877\n",
      "Epoch 10/100\n",
      "540000/540000 [==============================] - 10s 19us/sample - loss: 0.4134 - auc: 0.7914 - val_loss: 0.4152 - val_auc: 0.7871\n",
      "Epoch 11/100\n",
      "537600/540000 [============================>.] - ETA: 0s - loss: 0.4136 - auc: 0.7927Restoring model weights from the end of the best epoch.\n",
      "540000/540000 [==============================] - 11s 20us/sample - loss: 0.4136 - auc: 0.7927 - val_loss: 0.4171 - val_auc: 0.7865\n",
      "Epoch 00011: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "6it [13:03, 135.29s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 540000 samples, validate on 60000 samples\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "540000/540000 [==============================] - 14s 25us/sample - loss: 0.5449 - auc: 0.7111 - val_loss: 0.4627 - val_auc: 0.7801\n",
      "Epoch 2/100\n",
      "540000/540000 [==============================] - 11s 20us/sample - loss: 0.4502 - auc: 0.7770 - val_loss: 0.4339 - val_auc: 0.7813\n",
      "Epoch 3/100\n",
      "540000/540000 [==============================] - 11s 21us/sample - loss: 0.4290 - auc: 0.7818 - val_loss: 0.4234 - val_auc: 0.7818\n",
      "Epoch 4/100\n",
      "540000/540000 [==============================] - 11s 21us/sample - loss: 0.4217 - auc: 0.7838 - val_loss: 0.4201 - val_auc: 0.7816\n",
      "Epoch 5/100\n",
      "540000/540000 [==============================] - 12s 23us/sample - loss: 0.4198 - auc: 0.7847 - val_loss: 0.4195 - val_auc: 0.7814\n",
      "Epoch 6/100\n",
      "539648/540000 [============================>.] - ETA: 0s - loss: 0.4186 - auc: 0.7857\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "540000/540000 [==============================] - 11s 20us/sample - loss: 0.4186 - auc: 0.7858 - val_loss: 0.4190 - val_auc: 0.7818\n",
      "Epoch 7/100\n",
      "540000/540000 [==============================] - 10s 19us/sample - loss: 0.4126 - auc: 0.7892 - val_loss: 0.4163 - val_auc: 0.7807\n",
      "Epoch 8/100\n",
      "539648/540000 [============================>.] - ETA: 0s - loss: 0.4120 - auc: 0.7905Restoring model weights from the end of the best epoch.\n",
      "540000/540000 [==============================] - 11s 21us/sample - loss: 0.4120 - auc: 0.7906 - val_loss: 0.4176 - val_auc: 0.7808\n",
      "Epoch 00008: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "7it [15:24, 136.80s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 540000 samples, validate on 60000 samples\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "540000/540000 [==============================] - 15s 27us/sample - loss: 0.5518 - auc: 0.7059 - val_loss: 0.4636 - val_auc: 0.7865\n",
      "Epoch 2/100\n",
      "540000/540000 [==============================] - 10s 18us/sample - loss: 0.4533 - auc: 0.7760 - val_loss: 0.4324 - val_auc: 0.7872\n",
      "Epoch 3/100\n",
      "540000/540000 [==============================] - 9s 18us/sample - loss: 0.4310 - auc: 0.7808 - val_loss: 0.4209 - val_auc: 0.7871\n",
      "Epoch 4/100\n",
      "540000/540000 [==============================] - 10s 19us/sample - loss: 0.4229 - auc: 0.7831 - val_loss: 0.4190 - val_auc: 0.7875\n",
      "Epoch 5/100\n",
      "540000/540000 [==============================] - 10s 19us/sample - loss: 0.4212 - auc: 0.7843 - val_loss: 0.4177 - val_auc: 0.7872\n",
      "Epoch 6/100\n",
      "540000/540000 [==============================] - 10s 18us/sample - loss: 0.4202 - auc: 0.7850 - val_loss: 0.4164 - val_auc: 0.7867\n",
      "Epoch 7/100\n",
      "539648/540000 [============================>.] - ETA: 0s - loss: 0.4198 - auc: 0.7863\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "540000/540000 [==============================] - 10s 19us/sample - loss: 0.4198 - auc: 0.7863 - val_loss: 0.4174 - val_auc: 0.7869\n",
      "Epoch 8/100\n",
      "540000/540000 [==============================] - 10s 19us/sample - loss: 0.4136 - auc: 0.7899 - val_loss: 0.4144 - val_auc: 0.7859\n",
      "Epoch 9/100\n",
      "538624/540000 [============================>.] - ETA: 0s - loss: 0.4134 - auc: 0.7906Restoring model weights from the end of the best epoch.\n",
      "540000/540000 [==============================] - 11s 20us/sample - loss: 0.4134 - auc: 0.7907 - val_loss: 0.4157 - val_auc: 0.7857\n",
      "Epoch 00009: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "8it [17:45, 138.25s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 540000 samples, validate on 60000 samples\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "540000/540000 [==============================] - 14s 25us/sample - loss: 0.5510 - auc: 0.7080 - val_loss: 0.4631 - val_auc: 0.7834\n",
      "Epoch 2/100\n",
      "540000/540000 [==============================] - 11s 20us/sample - loss: 0.4535 - auc: 0.7761 - val_loss: 0.4347 - val_auc: 0.7844\n",
      "Epoch 3/100\n",
      "540000/540000 [==============================] - 10s 19us/sample - loss: 0.4306 - auc: 0.7819 - val_loss: 0.4226 - val_auc: 0.7841\n",
      "Epoch 4/100\n",
      "540000/540000 [==============================] - 11s 20us/sample - loss: 0.4225 - auc: 0.7839 - val_loss: 0.4196 - val_auc: 0.7832\n",
      "Epoch 5/100\n",
      "537600/540000 [============================>.] - ETA: 0s - loss: 0.4209 - auc: 0.7847\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "540000/540000 [==============================] - 10s 19us/sample - loss: 0.4208 - auc: 0.7847 - val_loss: 0.4188 - val_auc: 0.7832\n",
      "Epoch 6/100\n",
      "540000/540000 [==============================] - 10s 18us/sample - loss: 0.4145 - auc: 0.7879 - val_loss: 0.4162 - val_auc: 0.7827\n",
      "Epoch 7/100\n",
      "539648/540000 [============================>.] - ETA: 0s - loss: 0.4139 - auc: 0.7888Restoring model weights from the end of the best epoch.\n",
      "540000/540000 [==============================] - 11s 20us/sample - loss: 0.4139 - auc: 0.7889 - val_loss: 0.4164 - val_auc: 0.7825\n",
      "Epoch 00007: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "9it [19:46, 132.94s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 540000 samples, validate on 60000 samples\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "540000/540000 [==============================] - 13s 25us/sample - loss: 0.5539 - auc: 0.7017 - val_loss: 0.4648 - val_auc: 0.7831\n",
      "Epoch 2/100\n",
      "540000/540000 [==============================] - 10s 18us/sample - loss: 0.4537 - auc: 0.7756 - val_loss: 0.4351 - val_auc: 0.7837\n",
      "Epoch 3/100\n",
      "540000/540000 [==============================] - 10s 19us/sample - loss: 0.4304 - auc: 0.7814 - val_loss: 0.4224 - val_auc: 0.7840\n",
      "Epoch 4/100\n",
      "540000/540000 [==============================] - 11s 20us/sample - loss: 0.4222 - auc: 0.7833 - val_loss: 0.4188 - val_auc: 0.7839\n",
      "Epoch 5/100\n",
      "540000/540000 [==============================] - 10s 19us/sample - loss: 0.4199 - auc: 0.7843 - val_loss: 0.4173 - val_auc: 0.7839\n",
      "Epoch 6/100\n",
      "538624/540000 [============================>.] - ETA: 0s - loss: 0.4190 - auc: 0.7849\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "540000/540000 [==============================] - 10s 18us/sample - loss: 0.4191 - auc: 0.7849 - val_loss: 0.4175 - val_auc: 0.7838\n",
      "Epoch 7/100\n",
      "540000/540000 [==============================] - 10s 19us/sample - loss: 0.4134 - auc: 0.7876 - val_loss: 0.4142 - val_auc: 0.7835\n",
      "Epoch 8/100\n",
      "539648/540000 [============================>.] - ETA: 0s - loss: 0.4130 - auc: 0.7889Restoring model weights from the end of the best epoch.\n",
      "540000/540000 [==============================] - 11s 20us/sample - loss: 0.4130 - auc: 0.7888 - val_loss: 0.4158 - val_auc: 0.7830\n",
      "Epoch 00008: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "10it [21:57, 131.72s/it]\u001b[A\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "folds = 10\n",
    "skf = StratifiedKFold(n_splits=folds, shuffle=True, random_state=42)\n",
    "\n",
    "es = EarlyStopping(monitor='val_auc', min_delta=0.0001, patience=5, verbose=1, mode='max',  \n",
    "                   baseline=None,  restore_best_weights=True)\n",
    "\n",
    "rlr = ReduceLROnPlateau(monitor='val_auc', factor=0.5, patience=3, min_lr=1e-6, mode='max', verbose=1)\n",
    "\n",
    "df_test[\"target\"] = 0\n",
    "X_test = [df_test.loc[:, f].values for f in features]\n",
    "\n",
    "df_test[\"target\"] = 0\n",
    "\n",
    "scaller = StandardScaler()\n",
    "\n",
    "for train_idx, val_idx in tqdm(skf.split(df, df[\"target\"])):\n",
    "       \n",
    "    X_train = [scaller.fit_transform(df.loc[train_idx, features_enc].values)]\n",
    "    X_train += [df.loc[train_idx, f].values for f in features]\n",
    "    y_train = df.loc[train_idx, \"target\"].values\n",
    "    \n",
    "    X_val = [scaller.transform(df.loc[val_idx, features_enc].values)] \n",
    "    X_val += [df.loc[val_idx, f].values for f in features]\n",
    "    y_val = df.loc[val_idx, \"target\"].values\n",
    "    \n",
    "    model = create_model(df, features_enc, features)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=\"adam\", metrics=[auc])\n",
    "\n",
    "    model.fit(X_train, utils.to_categorical(y_train), validation_data=(X_val, utils.to_categorical(y_val)),\n",
    "              verbose=1, batch_size=1024, callbacks=[es, rlr], epochs=100)\n",
    "       \n",
    "    X_test = [scaller.transform(df_test.loc[:, features_enc].values)] \n",
    "    X_test += [df_test.loc[:, f].values for f in features]\n",
    "    df_test[\"target\"] += model.predict(X_test)[:, 1]\n",
    " \n",
    "    K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id,target\r\n",
      "600000,0.14275625\r\n",
      "600001,0.2633614\r\n",
      "600002,0.1735541\r\n",
      "600003,0.14033902\r\n"
     ]
    }
   ],
   "source": [
    "# df_test['target'] /= folds\n",
    "# df_test[['id', 'target']].to_csv('../data/submission_entity_encoding_2.csv', index=False)\n",
    "# !head -n 5 ../data/submission_entity_encoding.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine submissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id,target\r\n",
      "600000,0.12703491030357303\r\n",
      "600001,0.26469590910102686\r\n",
      "600002,0.1769536913258547\r\n",
      "600003,0.11936844049592421\r\n"
     ]
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "# df1 = pd.read_csv('../data/submission_entity_encoding_2.csv')\n",
    "# df2 = pd.read_csv('../data/submission_lgbm.csv')\n",
    "# df2[\"target\"] = (df1[\"target\"] + df2[\"target\"])/2\n",
    "# df2.to_csv('../data/submission_combine.csv', index=False)\n",
    "# !head -n 5 ../data/submission_combine.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "!open ../"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
